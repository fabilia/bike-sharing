{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import google cloud library\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new prediction data\n",
    "new_test_data = pd.DataFrame({\n",
    "    'humidity': [0.28,0.5],\n",
    "    'weather': [1,3],\n",
    "    'holiday': [0,0],\n",
    "    'season': [1,3],\n",
    "    'temperature': [0.7,0.7],\n",
    "    'hour': [15,3],\n",
    "    'dayofweek': [6,0],\n",
    "    'month': [10,6],\n",
    "    'year': [2011,2012],\n",
    "})\n",
    "\n",
    "new_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate services account\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/home/e2102ta/safira-001/sa-development.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'dti-ds'\n",
    "dataset_id = 'safira_dataset_001'\n",
    "table_id = 'X_test'\n",
    "region = 'us-central1'\n",
    "bucket_name = 'safira_gcs_001'\n",
    "blob_name = 'data/X_test.csv'\n",
    "\n",
    "model_name = 'bike_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from BQ\n",
    "from google.cloud import bigquery\n",
    "## using bigquery client \n",
    "# client = bigquery.Client(credentials=credentials,project=project_id)\n",
    "client = bigquery.Client(project='dti-ds')\n",
    "\n",
    "# query \n",
    "query_job = client.query(f\"\"\"select * from {dataset_id}.{table_id}\"\"\")\n",
    "auto_cloud = query_job.result().to_dataframe()\n",
    "\n",
    "#cleansing \n",
    "result = auto_cloud.drop(['int64_field_0'], axis = 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open('bike_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "y_pred_cloud_new_data = loaded_model.predict(new_test_data)\n",
    "y_pred_cloud_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_cloud = new_test_data.copy()\n",
    "new_test_cloud['Count Predict'] = y_pred_cloud_new_data # new column\n",
    "new_test_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.predict(X_test.iloc[3:13])\n",
    "y_pred_file_cloud = loaded_model.predict(auto_cloud)\n",
    "y_pred_file_cloud[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Count Predict'] = y_pred_file_cloud # new column\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = 'X_test_predicted'\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define the full table ID\n",
    "table_full_id = f\"{client.project}.{dataset_id}.{table_id}\"\n",
    "\n",
    "result.columns = ['_'.join(i.split(' ')) for i in result.columns] # make sure no empty space on columns' name\n",
    "\n",
    "# Create the table\n",
    "# table = bigquery.Table(table_full_id)\n",
    "# table = client.create_table(table, exists_ok=True)\n",
    "# print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "\n",
    "# Load the DataFrame into the BigQuery table\n",
    "job = client.load_table_from_dataframe(result, table_full_id) # your df predicted name, and table full id above\n",
    "\n",
    "# Wait for the job to complete\n",
    "job.result()\n",
    "print(f\"Loaded {job.output_rows} rows into {table_full_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
